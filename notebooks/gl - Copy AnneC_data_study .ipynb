{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dressed-gentleman",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T08:20:01.260868Z",
     "start_time": "2021-04-26T08:20:01.184748Z"
    }
   },
   "outputs": [],
   "source": [
    "# Enable autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Pylint parameters\n",
    "%config Completer.use_jedi = False\n",
    "\n",
    "# Measure Runtime\n",
    "# !pip install ipython-autotime\n",
    "# %load_ext autotime\n",
    "\n",
    "# Mute warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metric-panama",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T08:20:04.548966Z",
     "start_time": "2021-04-26T08:20:01.269174Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exempt-absorption",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T08:20:04.802799Z",
     "start_time": "2021-04-26T08:20:04.554241Z"
    }
   },
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rental-ending",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T08:20:05.173321Z",
     "start_time": "2021-04-26T08:20:04.808379Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../raw_data/shopee-product-matching/train.csv') \n",
    "test_data = pd.read_csv('../raw_data/shopee-product-matching/test.csv')\n",
    "ss_data = pd.read_csv('../raw_data/shopee-product-matching/sample_submission.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lucky-swift",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T08:20:05.251921Z",
     "start_time": "2021-04-26T08:20:05.177904Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = train_data.copy()\n",
    "test_df = train_data.copy()\n",
    "ss_df = train_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecological-workplace",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T08:20:05.336448Z",
     "start_time": "2021-04-26T08:20:05.256266Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "copyrighted-extra",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T08:20:05.447480Z",
     "start_time": "2021-04-26T08:20:05.352817Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experimental-association",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T08:20:05.575179Z",
     "start_time": "2021-04-26T08:20:05.458183Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "administrative-healthcare",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T08:20:05.677977Z",
     "start_time": "2021-04-26T08:20:05.581099Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "catholic-slave",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T08:20:05.765453Z",
     "start_time": "2021-04-26T08:20:05.685262Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df['image'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competitive-yemen",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T08:20:05.970038Z",
     "start_time": "2021-04-26T08:20:05.772392Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "written-malta",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T08:20:06.078103Z",
     "start_time": "2021-04-26T08:20:05.975985Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confident-clear",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T08:20:06.150314Z",
     "start_time": "2021-04-26T08:20:06.085701Z"
    }
   },
   "outputs": [],
   "source": [
    "# pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continental-michigan",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T08:20:06.435251Z",
     "start_time": "2021-04-26T08:20:06.155614Z"
    }
   },
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "local-surfing",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T08:20:06.513042Z",
     "start_time": "2021-04-26T08:20:06.441013Z"
    }
   },
   "outputs": [],
   "source": [
    "def trans_img(file_name):\n",
    "    filename = os.path.abspath(os.path.join('../raw_data/shopee-product-matching/train_images', file_name))\n",
    "    return io.imread(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "buried-archive",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T08:20:06.657776Z",
     "start_time": "2021-04-26T08:20:06.519588Z"
    }
   },
   "outputs": [],
   "source": [
    "img_1 = trans_img('00039780dfc94d01db8676fe789ecd05.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conventional-bacteria",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T08:20:07.456528Z",
     "start_time": "2021-04-26T08:20:06.664430Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(img_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crazy-rings",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minute-expert",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "minus-sigma",
   "metadata": {},
   "source": [
    "# Image preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amateur-milwaukee",
   "metadata": {},
   "source": [
    "## Resizing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functional-tyler",
   "metadata": {},
   "source": [
    "We want to reshape the images in smaller size (state-of-the-art networks are trained on (224,224,3) images / tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "violent-collar",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T08:20:07.543881Z",
     "start_time": "2021-04-26T08:20:07.462388Z"
    }
   },
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "import os\n",
    "\n",
    "def get_img_size():\n",
    "    images = [image for image in train_df['image']]\n",
    "    img_shape = []\n",
    "    for image in images[11:76]:\n",
    "        img = trans_img(image)\n",
    "        x = img.shape\n",
    "        img_shape.append(x)\n",
    "        size_img = pd.DataFrame(img_shape)\n",
    "    return size_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retired-belly",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T08:20:11.492357Z",
     "start_time": "2021-04-26T08:20:07.551332Z"
    }
   },
   "outputs": [],
   "source": [
    "img_size_df = get_img_size()\n",
    "img_size_df.sort_values(by=0, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plastic-above",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T08:20:11.582903Z",
     "start_time": "2021-04-26T08:20:11.498475Z"
    }
   },
   "outputs": [],
   "source": [
    "max(img_size_df[1]), min(img_size_df[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strategic-surfing",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T08:20:11.684251Z",
     "start_time": "2021-04-26T08:20:11.593733Z"
    }
   },
   "outputs": [],
   "source": [
    "sizes_set = set(img_size_df[0])\n",
    "def sizes_ratio():\n",
    "    for size in sizes_set:\n",
    "        return img_size_df[0].value_counts()/len(train_df['image'])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spoken-perception",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T08:20:11.772145Z",
     "start_time": "2021-04-26T08:20:11.707031Z"
    }
   },
   "outputs": [],
   "source": [
    "len(sizes_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comfortable-german",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T08:20:11.884654Z",
     "start_time": "2021-04-26T08:20:11.790830Z"
    }
   },
   "outputs": [],
   "source": [
    "x = sizes_ratio()\n",
    "x.sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unauthorized-example",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T08:20:11.962541Z",
     "start_time": "2021-04-26T08:20:11.889517Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_unsquarred_ratio() :\n",
    "    records = img_size_df.to_records(index=False)\n",
    "    list_sizes = list(records)\n",
    "    print(list_sizes)\n",
    "    unsquarred =[]\n",
    "    for x in list_sizes:\n",
    "        if x[0]!=x[1]:\n",
    "            unsquarred.append(x[0])\n",
    "    return f\"Ratio of unsquarred images : {round(len(unsquarred)/len(train_df['image']), 3)*100} %\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driven-trail",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T08:20:12.065277Z",
     "start_time": "2021-04-26T08:20:11.969423Z"
    }
   },
   "outputs": [],
   "source": [
    "get_unsquarred_ratio()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuck-cornell",
   "metadata": {},
   "source": [
    "Turning images into arrays of size (224, 224, 3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blessed-helicopter",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T08:20:12.157975Z",
     "start_time": "2021-04-26T08:20:12.072356Z"
    }
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def drop_unsquarred():\n",
    "    df_squarred = []\n",
    "    images = [image for image in train_df['image']]\n",
    "    for image in images:\n",
    "        image_size=Image.open(f\"../raw_data/shopee-product-matching/train_images/{image}\").size\n",
    "        if image_size[0] == image_size[1]:\n",
    "            df_squarred.append(image)\n",
    "    return df_squarred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promising-penny",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T08:20:41.298412Z",
     "start_time": "2021-04-26T08:20:12.165509Z"
    }
   },
   "outputs": [],
   "source": [
    "df_squarred = drop_unsquarred()\n",
    "df_squarred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worse-reply",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T08:20:41.363102Z",
     "start_time": "2021-04-26T08:20:41.302678Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def resize_save_unsquarred():\n",
    "    img_squarred = []\n",
    "    for image in df_squarred:\n",
    "        image_open=Image.open(f\"../raw_data/shopee-product-matching/train_images/{image}\").resize((100,100))\n",
    "        image_open.save(f\"../raw_data/shopee-product-matching/train_images/resized/{image}\")\n",
    "        img_squarred.append(image_open)\n",
    "    return img_squarred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distributed-privilege",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T08:37:43.435312Z",
     "start_time": "2021-04-26T08:20:41.369012Z"
    }
   },
   "outputs": [],
   "source": [
    "img_squarred = resize_save_unsquarred()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documented-mounting",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T08:37:44.021565Z",
     "start_time": "2021-04-26T08:37:43.451323Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(img_squarred[1100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nearby-fourth",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T08:37:44.115117Z",
     "start_time": "2021-04-26T08:37:44.026074Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_df['resized_image'] = pd.read_csv('../raw_data/shopee-product-matching/train_images/resized/train.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "after-cache",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funky-characteristic",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T08:37:52.328097Z",
     "start_time": "2021-04-26T08:37:44.119812Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Minimal Network + Common tricks + First hyperparameters tests\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "# First convolution & max-pooling\n",
    "model.add(layers.Conv2D(100, (10,4), strides=(2,2), input_shape=(28, 28, 1), padding='same'))\n",
    "model.add(layers.MaxPool2D(pool_size=(3,3)))\n",
    "\n",
    "# Second convolution & max-pooling\n",
    "model.add(layers.Conv2D(32, (3,3), strides=(2,2), padding='same'))\n",
    "model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(100, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# ––– This is where your Data Scientist skills begin"
   ]
  },
  {
   "cell_type": "raw",
   "id": "closing-adrian",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finnish-joint",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protected-caribbean",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T10:21:18.322522Z",
     "start_time": "2021-04-26T10:21:18.253737Z"
    }
   },
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "from skimage import io\n",
    "import os\n",
    "\n",
    "def resize_images():\n",
    "    images = [image for image in train_df['image']]\n",
    "    # img_shape = []\n",
    "    for image in images[0:10]:\n",
    "        image_path =  f'{image}'\n",
    "        filename = os.path.abspath(os.path.join('../raw_data/shopee-product-matching/train_images/resized/', image_path))\n",
    "        img = io.imread(filename)\n",
    "        x = img.shape\n",
    "        # img_shape.append(x)\n",
    "        # print(x)\n",
    "        # print(img_shape)\n",
    "        # size_img = pd.DataFrame(img_shape)\n",
    "        # print(size_img)\n",
    "        # print(img_shape)\n",
    "        # for img in size_img.loc[0,[0, 1]]:\n",
    "            #print(img[0],img[1])\n",
    "        #image_resized = resize(img, (img_shape[0][0] // img_shape[0][0] * 100, img_shape[0][1] // img_shape[0][1] * 100), anti_aliasing=True)\n",
    "        # train_df['shape_resized'] = x\n",
    "    return train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disabled-transsexual",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T10:21:19.883754Z",
     "start_time": "2021-04-26T10:21:19.756280Z"
    }
   },
   "outputs": [],
   "source": [
    "resize_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gorgeous-dealer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "overall-nirvana",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Intensity normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occasional-guide",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Neural networks converge faster if the inputs are somewhat normalized. Therefore we want to transform the image pixels with values between 0 and 255 (for each color) into values between -1 and 1, thanks to Keras libraries (or just by dividing all the data by 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "right-render",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pursuant-technique",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "announced-voltage",
   "metadata": {},
   "source": [
    "## Data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gentle-measurement",
   "metadata": {},
   "source": [
    "Creation of additionnal data to explore : \n",
    "- Mirror\n",
    "- Crop\n",
    "- rotations\n",
    "- slight transformation of the colors\n",
    "- change of the textures\n",
    "- \"photoshop effects\": blur, halo, ...\n",
    "- deformations\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "professional-plastic",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powered-killer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "universal-litigation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proprietary-greenhouse",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T08:37:53.749741Z",
     "start_time": "2021-04-26T08:20:01.612Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Reshape\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Reshape((5*5*1,), input_shape=(5,5,1)))  # This flattens the (5, 5, 1) image to a vector of size 25\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "received-opposition",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressive-wealth",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "applied-companion",
   "metadata": {},
   "source": [
    "# Preprocessing on titles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enhanced-priest",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T08:37:53.753709Z",
     "start_time": "2021-04-26T08:20:01.627Z"
    }
   },
   "outputs": [],
   "source": [
    "# pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "american-stamp",
   "metadata": {},
   "source": [
    "- Lowercase\n",
    "- remove numbers\n",
    "- remove punctuation\n",
    "- remove stop words\n",
    "- select important words with stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alien-merit",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T08:37:53.756849Z",
     "start_time": "2021-04-26T08:20:01.636Z"
    }
   },
   "outputs": [],
   "source": [
    "#labels\n",
    "print(f\"label_group unique values: {train_df['label_group'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lightweight-insert",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T08:37:53.759751Z",
     "start_time": "2021-04-26T08:20:01.642Z"
    }
   },
   "outputs": [],
   "source": [
    "groups_df = train_df[\"label_group\"].value_counts().reset_index()\n",
    "groups_df.columns = [\"group\", \"count\"]\n",
    "print(\"Max no. of apparitions in 1 group: {}\".format(groups_df[\"count\"].max()), \"\\n\" +\n",
    "      \"Min no. of apparitions in 1 group: {}\".format(groups_df[\"count\"].min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepted-synthesis",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T08:37:53.762646Z",
     "start_time": "2021-04-26T08:20:01.648Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot labels distribution\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize = (12, 6))\n",
    "plt.title('Group Count Distribution', fontsize = '15')\n",
    "sns.kdeplot(groups_df['count'], fill = True, \n",
    "            color = '#f15335', \n",
    "            edgecolor = 'black', alpha = 0.9)\n",
    "plt.xlabel('Label count')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signed-superior",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T08:37:53.765928Z",
     "start_time": "2021-04-26T08:20:01.654Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot titles length distribution\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize = (12, 6))\n",
    "plt.title('Distribution of title length', fontsize = '15')\n",
    "sns.kdeplot(train_df['title'].apply(lambda x: len(x)), fill = True, \n",
    "            color = '#f15335', \n",
    "            edgecolor = 'black', alpha = 0.9)\n",
    "plt.xlabel('Title length')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "discrete-milan",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T08:37:53.768721Z",
     "start_time": "2021-04-26T08:20:01.660Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install -U textblob\n",
    "# !python -m textblob.download_corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "racial-cooling",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T08:37:53.774926Z",
     "start_time": "2021-04-26T08:20:01.667Z"
    }
   },
   "outputs": [],
   "source": [
    "import string \n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from textblob import TextBlob\n",
    "\n",
    "unpreproc_title = train_df[\"title\"][1]\n",
    "print(f\"Before: {unpreproc_title}\")\n",
    "lower_title = unpreproc_title.lower()\n",
    "print(f\"Lower case: {lower_title}\")\n",
    "punct = \"!”#$%&’()*+,-./:;<=>?@[\\]^_`{|}~]:\"\n",
    "rem_punct = lower_title.translate(str.maketrans('','',string.punctuation))\n",
    "print(f\"Remove punctuation: {rem_punct}\")\n",
    "rem_whitespaces = rem_punct.strip()\n",
    "print(f\"Remove whitespaces: {rem_whitespaces}\")\n",
    "tokenize = word_tokenize(rem_whitespaces)\n",
    "print(f\"Tokenized: {tokenize}\")\n",
    "rem_stop_words = [word for word in tokenize if not word in stopwords.words()]\n",
    "print(f\"Remove stopwords: {rem_stop_words}\")\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_text = [lemmatizer.lemmatize(word) for word in rem_stop_words]\n",
    "print(f\"Lemmatization: {lemmatized_text}\")\n",
    "pos_text = TextBlob(' '.join(lemmatized_text))\n",
    "print(f\"Part_Of_Speech: {pos_text.tags}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adopted-patio",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T08:37:53.778346Z",
     "start_time": "2021-04-26T08:20:01.672Z"
    }
   },
   "outputs": [],
   "source": [
    "def preproc_title(title):\n",
    "    title = title.lower()\n",
    "    title = title.translate(str.maketrans('','',string.punctuation))\n",
    "    title = title.strip()\n",
    "    tokens_title = word_tokenize(title)\n",
    "    tokens_title = [word for word in tokens_title if not word in stopwords.words()]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemm_text = [lemmatizer.lemmatize(word) for word in tokens_title]\n",
    "    preproc_title = ' '.join(lemm_text)\n",
    "    return preproc_title\n",
    "\n",
    "def get_part_of_speech(prepped_title):\n",
    "    part_of_speech = TextBlob(prepped_title)\n",
    "    part_of_speech = ' '.join([j for (i, j) in pos_text.tags])\n",
    "    return part_of_speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "local-flash",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T08:37:53.781223Z",
     "start_time": "2021-04-26T08:20:01.678Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df[\"preproc_title\"] = train_df[\"title\"].apply(lambda x: preproc_title(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protecting-pendant",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T08:37:53.784882Z",
     "start_time": "2021-04-26T08:20:01.682Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df[\"part_of_speech\"] = train_df[\"preproc_title\"].apply(lambda x: get_part_of_speech(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "three-favorite",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T08:37:53.789591Z",
     "start_time": "2021-04-26T08:20:01.688Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read in prepped data\n",
    "# train_df_prep = pd.read_csv(\"../raw_data/shopee-preprocessed-data/train_title_prepped.csv\")\n",
    "# train_df_prep[\"label_group\"] = train_df_prep[\"label_group\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acquired-faculty",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "457.5px",
    "left": "1437.5px",
    "right": "20px",
    "top": "120px",
    "width": "342.5px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
